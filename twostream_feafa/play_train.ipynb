{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 24 11:06:30 EDT 2023\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/aglinska/BC-actionpred-seg/twostream_feafa'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'feafa_criterion' from '/mmfs1/data/aglinska/BC-actionpred-seg/twostream_feafa/feafa_criterion.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "from math import exp\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import feafa_utils\n",
    "import feafa_dataloader\n",
    "import feafa_architecture\n",
    "import feafa_criterion\n",
    "\n",
    "reload(feafa_utils)\n",
    "reload(feafa_dataloader)\n",
    "reload(feafa_architecture)\n",
    "reload(feafa_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "#path = \"/mmfs1/data/anzellos/data/FEAFA2\"\n",
    "path = '/data/aglinska/BC-actionpred-seg/Data/pytorch-data/xl_121_15_action_data_orig/train/'\n",
    "window = 11\n",
    "traindataset = feafa_dataloader.FeafaDataset(path,window,usage='Train')\n",
    "trainloader = DataLoader(traindataset,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet = feafa_architecture.TinyMotionNet()\n",
    "flownet.cuda()\n",
    "flownet.train()\n",
    "\n",
    "reconstructor = feafa_utils.Reconstructor()\n",
    "\n",
    "criterion = feafa_criterion.SimpleLoss(flownet)\n",
    "\n",
    "optimizer = optim.SGD(flownet.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "#save_root = \"/data/anzellos/results/twostream_feafa\"\n",
    "save_root = \"/data/aglinska/BC-actionpred-seg/Data/02-results_twostream_feafa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch  0  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_freq = 1                               # specify every how many epochs to save the model\n",
    "loss_memory = []\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    print('Starting epoch ',epoch,' ...\\n')\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        frames = data['frames'].cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "        flows = flownet(frames)\n",
    "        t0s, reconstructed, flows_reshaped = reconstructor(frames, flows) # t0s are original images excluding the 11th, downsampled to match the reconstructed versions\n",
    "        # zero the parameter gradients\n",
    "        frames.detach().cpu()\n",
    "        for flow in flows:\n",
    "            flow.detach().cpu()\n",
    "        del flows,frames\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        loss = criterion(t0s,reconstructed,flows_reshaped,flownet)\n",
    "        for t0 in t0s:\n",
    "            t0.detach().cpu()\n",
    "        for reco in reconstructed:\n",
    "            reco.detach().cpu()\n",
    "        for flore in flows_reshaped:\n",
    "            flore.detach().cpu()\n",
    "        del t0s,reconstructed,flows_reshaped\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.data.item()\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    print('[%d] loss: %.3f' %(epoch + 1, epoch_loss ))\n",
    "    # loss_memory.append(epoch_loss)\n",
    "    running_loss = 0.0\n",
    "    if epoch % save_freq == save_freq-1: \n",
    "        savename = f'epoch{epoch+1:05d}.ckp'\n",
    "        save_path = os.path.join(save_root,savename)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': flownet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': epoch_loss\n",
    "            }, save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
